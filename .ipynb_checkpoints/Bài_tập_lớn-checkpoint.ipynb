{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04a0832-fbba-4322-bbff-ece25128d537",
   "metadata": {},
   "source": [
    "<h1><center>Bài tập lớn nhập môn học máy và khai phá dữ liệu</center></h1>\n",
    "<h2><center>Đề tài: Phân loại tiêu đề bài báo</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718254cd-c64d-46aa-8906-eb16c6876d0c",
   "metadata": {},
   "source": [
    "### Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162b5aca-a0c6-46ff-a047-f06794e5a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from TextPreprocess import text_process\n",
    "import string\n",
    "from underthesea import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48bfa5-761a-4b07-96db-7b7aa25f59d6",
   "metadata": {},
   "source": [
    "### Lấy dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5370229-4c1c-4245-926b-1c830c826110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data.csv', names=['label', 'title'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e185ce-26c4-42e2-9bb7-88aaa7c5bc1d",
   "metadata": {},
   "source": [
    "### Mô tả dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426d56bb-09ff-4f90-9043-9f34349506a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1981</td>\n",
       "      <td>Khẩu trang</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Băng rừng leo đỉnh Nhìu Cồ San</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1995</td>\n",
       "      <td>Thúy Diễm</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1992</td>\n",
       "      <td>Thử thách suy luận với bốn câu đố</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Hệ thống giúp tàu không trượt bánh khi trời mưa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>1978</td>\n",
       "      <td>Giá xăng</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>1995</td>\n",
       "      <td>Đốt nhà mình</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>1987</td>\n",
       "      <td>Nguyên nhân</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>1990</td>\n",
       "      <td>Messi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>1989</td>\n",
       "      <td>Nhiều tỉnh</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                                              \n",
       "      count unique                                               top freq\n",
       "label                                                                    \n",
       "1      2000   1981                                        Khẩu trang    5\n",
       "2      2000   2000                    Băng rừng leo đỉnh Nhìu Cồ San    1\n",
       "3      2000   1995                                         Thúy Diễm    2\n",
       "4      2000   1992                 Thử thách suy luận với bốn câu đố    2\n",
       "5      2000   2000   Hệ thống giúp tàu không trượt bánh khi trời mưa    1\n",
       "6      2000   1978                                          Giá xăng    5\n",
       "7      2000   1995                                      Đốt nhà mình    2\n",
       "8      2000   1987                                       Nguyên nhân    3\n",
       "9      2000   1990                                             Messi    4\n",
       "10     2000   1989                                        Nhiều tỉnh    3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320a1c3-8cab-4ba9-95a8-20c2cf28695c",
   "metadata": {},
   "source": [
    "### Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9bfca-825c-4c21-bb61-220b7c80ee33",
   "metadata": {},
   "source": [
    "+ Vấn đề chính bây giờ là dữ liệu đang ở định dạng văn bản (string). Thuật toán phân loại (classification) chỉ hoạt động dưới dạng dữ liệu số hóa (numeric), từ đó yêu cầu phải chuyển đổi dữ liệu đầu vào trên (chuỗi kí tự) thành vector (chuỗi số) để các thuật toán học máy có thể hiểu được\n",
    "+ Bước đầu tiên, chia các đoạn tin nhắn thành các từ riêng lẻ, rồi lưu chúng vào list\n",
    "+ Tách từ trong câu thành từ đơn, từ ghép nhằm tăng ý nghĩa của từ, giảm features. Dùng thư viện underthesea\n",
    "+ Chuyển các số phần trăm (vd 20%, 10%, 0.5%...) thành 'percents' nhằm giảm features\n",
    "+ Xóa các kí tự \n",
    "+ Chuyển các số thành 'numbers', ngày tháng thành 'days' nhằm giảm features\n",
    "+ Loại bỏ stopword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b85fb3-c3cf-46d9-94e7-fe4c4d868c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d359c6-e46f-44af-a561-cac54113025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm lấy stopword\n",
    "def stop_word():\n",
    "    file = open(r'stopword.txt', 'r', encoding='utf-8')\n",
    "    # file = open(r'vietnamese-stopwords.txt', 'r', encoding='utf-8')\n",
    "    stopwords = []\n",
    "    for line in file:\n",
    "        stopwords.append(line.replace(\"\\n\", \"\"))\n",
    "    file.close()\n",
    "\n",
    "    punc = string.punctuation.replace(\"_\", \"\").replace(\"/\", \"\").replace(\"%\", \"\") + '‘’'\n",
    "    return stopwords, punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b1d51d-08bd-4176-b68e-ddea1aeb77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tiền xử lý dữ liệu: trả về list các từ sau khi được xử lý\n",
    "def text_process(line):\n",
    "    stopwords, punc = stop_word()\n",
    "    a = line.split()\n",
    "    for i, x in enumerate(a):\n",
    "        for j in a[i]:\n",
    "            if j == '%':\n",
    "                a[i] = 'percents'\n",
    "                break\n",
    "    line = ' '.join(a)\n",
    "    str = word_tokenize(line, format=\"text\").lower()\n",
    "    # str = line.lower()\n",
    "    words = [char for char in str if char not in punc]\n",
    "    words = ''.join(words)\n",
    "    words = words.split()\n",
    "    n = len(words)\n",
    "    for i in range(n):\n",
    "        for j in words[i]:\n",
    "            if j == '/':\n",
    "                words[i] = 'days'\n",
    "                break\n",
    "        try:\n",
    "            float(words[i])\n",
    "            words[i] = 'numbers'\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    word = []\n",
    "    for w in words:\n",
    "        if w not in stopwords:\n",
    "            word.append(w)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accb985-7d99-4a46-a9a0-6fe271132f14",
   "metadata": {},
   "source": [
    "# Thuật toán Text search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3092b3-526c-44ff-a3d6-2d1b754e84fe",
   "metadata": {},
   "source": [
    "### Vectorization (vector hóa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f831c-1b7b-42e1-b984-afbef700c17a",
   "metadata": {},
   "source": [
    "Bây giờ các văn bản đã được mã hóa, chúng ta cần chuyển đổi chúng thành các vector để các thuật toán học máy trong SciKit Learn có thể làm việc được.\n",
    "\n",
    "Chúng ta sẽ thực hiện điều đó trong 3 bước bằng cách sử dụng mô hình bag-of-words:\n",
    "1. Đếm xem bao nhiêu lần một từ xuất hiện trong mỗi đoạn tin nhắn - được gọi là hiểu tần suất thuật ngữ (Known as term frequency)\n",
    "2. Xuy xét các số lượng trên, các mã xuất hiện thường xuyên sẽ có trọng số thấp hơn (inverse document frequency)\n",
    "3. Chuẩn hóa các vector thành độ dài đơn vị, để tóm tắt từ độ dài văn bản ban đầu (L2 norm)\n",
    "+ Chuẩn $l_2$ của vector $ \\textbf{v} $  chứa $n$ phần tử:\n",
    "$$ \\textbf{||v|| = $\\sqrt{|v_0|^2 + |v_1|^2 + ... + |v_n|^2}$} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d939390-e9e9-4463-9544-d703af0ba8ea",
   "metadata": {},
   "source": [
    "Mỗi vector đều có rất nhiều chiều, ta sẽ sử dụng **CountVectorizer** của thư viện SciKit-Learn. Model này sẽ chuyển đổi các bộ văn bản thành một ma trận số lượng mã hóa\n",
    "\n",
    "Có thể hình dung đây là một ma trận 2 chiều. Trong đó chiều thứ nhất là toàn bộ từ vựng (1 hàng tương ứng với 1 từ), còn chiều còn lại là các văn bản thực tế (mỗi cột là một tin nhắn văn bản)\n",
    "\n",
    "Ví dụ:\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "Bởi vì có rất nhiều tin nhắn, nên số lượng số 0 xuất hiện trong ma trận là rất nhiều, do đó ma trận trả về sẽ là một ma trận thưa thớt (Sparse Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc92572-fac6-46cd-9b84-032853a033ca",
   "metadata": {},
   "source": [
    "Có rất nhiều đối số và tham số có thể truyền vào **CountVectorizer**, trong trường hợp này ta chỉ định **analyzer** chính là hàm **text_process** ta đã tạo ra trước đó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eec081-6803-4247-883f-2f8109257d0e",
   "metadata": {},
   "source": [
    "#### Vector hóa với thư viện scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9da8456-1032-4a1f-b96d-2d9f40146131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_vector = CountVectorizer(analyzer=text_process).fit(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb87485-5810-4cd3-94bb-6889f7105b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem tổng số từ vựng\n",
    "# len(data_vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6503815-588f-4a71-96b0-3f9cb84b7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử biểu diễn dữ liệu\n",
    "# data_test = df['title'][1]\n",
    "# print(data_test)\n",
    "# print(text_process(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c9a66d-91e4-451f-8cd5-90395c1538dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biểu diễn thành vector\n",
    "# bow = data_vector.transform([data_test])\n",
    "# print(bow)\n",
    "# print(bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50361b9e-a73e-42e1-80a4-96bcb07d6ceb",
   "metadata": {},
   "source": [
    "Giờ ta sẽ sử dụng **.transform** trên đối tượng đã được biến đổi \"Bag-of-Words (bow_transformer)\" để chuyển đổi dataframe ban đầu thành một Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296a9af1-aa7c-406a-8ec8-aaf178e441f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages_bow = data_vector.transform(df['title'])\n",
    "# messages_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7478f16-33e5-46eb-96e7-4236545ec26b",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "Sau khi đếm, trọng số và chuẩn hóa thuật ngữ có thể được thực hiện với TF-IDF, sử dụng **TfidfTransformer** của SciKit-Learn\n",
    "### TF-IDF là gì ?\n",
    "Trong truy hồi thông tin, tf-idf (term frequency–inverse document frequency) là một thống kê số học nhằm phản ánh tầm quan trọng của một từ đối với một văn bản trong một tập hợp hay một ngữ liệu văn bản. tf–idf thường dùng dưới dạng là một trọng số trong tìm kiếm truy xuất thông tin, khai thác văn bản, và mô hình hóa người dùng.\n",
    "\n",
    "Giá trị tf–idf tăng tỉ lệ thuận với số lần xuất hiện của một từ trong tài liệu và được bù đắp bởi số lượng tài liệu trong kho ngữ liệu có chứa từ, giúp điều chỉnh thực tế là một số từ xuất hiện nói chung thường xuyên hơn. tf-idf là một trong những lược đồ (scheme) tính trọng số phổ biến nhất hiện nay. \n",
    "1. **TF-term frequency** - tần số xuất hiện của 1 từ trong 1 văn bản. Cách tính như sau:\n",
    "\n",
    "$$\\mbox{tf}(t,d) = \\frac{\\mbox{f}(t,d)}{max\\{\\mbox{f}(w,d): w\\in d\\}}$$\n",
    "+ Kết quả thuộc khoảng $[0,1]$, thuơng của số lần xuất hiện 1 từ trong văn bản và số lần xuất hiện nhiều nhất của 1 từ trong văn bản đó\n",
    "+ $f(t,d)$: Tần suất của từ t trong văn bản $d$\n",
    "+ $max\\{f(w,d): w\\in d\\}$: số lần xuất hiện nhiều nhất của 1 từ trong $d$\n",
    "\n",
    "2. **IDF-inverse document frequency** - Tần số nghịch của một từ trong tập văn bản (corpus). Tính **IDF** để giảm giá trị của những từ phổ biến. Mỗi từ chỉ có 1 **IDF** duy nhất trong tập văn bản. Cách tính như sau: \n",
    "\n",
    "    $$\\mbox{idf}(t,D) = \\log\\frac{|D|}{1+|\\{d\\in D : t\\in d\\}|}$$\n",
    "+ $|D|$: Tổng số văn bản trong D\n",
    "+ $|\\{d\\in D : t\\in d\\}|$: Số văn bản chứa từ nhất định, với điều kiện $t$ xuất hiện trong văn bản $d$\n",
    "\n",
    "Cơ số logarit không thay đổi giá trị của 1 từ mà chỉ thu hẹp khoảng giá trị của từ đó (thay đổi cơ số không ảnh hưởng tới tỷ lệ giữa các IDF). Tuy nhiên thay đổi khoảng giá trị sẽ giúp tỷ lệ IDF và TF tương đồng để dùng cho công thức TF-IDF như bên dưới.\n",
    "\n",
    "$$\\mbox{tfidf}(t,d,D) = \\mbox{tf}(t,d) \\times \\mbox{idf}(t,D)$$\n",
    "\n",
    "Những từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, và xuất hiện ít trong các văn bản khác. Việc này giúp lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ khoá của văn bản đó).\n",
    "\n",
    "##### Ứng dụng\n",
    "IDF có ứng dụng phổ biến nhất trong tìm kiếm. Ví dụ như chúng ta muốn mua hàng ở shopee, chúng ta thực hiện truy vấn: \"Những món quà đẹp tặng người yêu ngày valentine\". Sau khi tách từ, những từ \"người yêu\" và \"valentine\" chắc chắn là những có idf cao nhất trong văn bản trên, từ đó hệ thống sẽ coi những từ trên là từ khóa, lấy tất cả các văn bản có chưa từ \"người yêu\" và \"valentine\" sau đó thực hiện đánh giá và so sánh dựa trên bộ truy vấn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b038c694-2692-44e3-9a9a-2ba4d1a77585",
   "metadata": {},
   "source": [
    "#### Thực hiện với scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352229cf-d3a3-4006-8acd-4cbc60689dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_transformer = TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bdb67f-7df3-47b8-855b-8e95d2c75b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf/idf với tiều đề \"9 món ăn sáng truyền thống ở Thái Lan\"\n",
    "# tfidf = tfidf_transformer.transform(bow)\n",
    "# print(tfidf) # Tính tfidf của tiêu đề \"9 món ăn sáng truyền thống ngon nhất Thái Lan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c870e8-57b6-4a2f-8b54-8bd839ca5b14",
   "metadata": {},
   "source": [
    "# Tách dữ liệu thành training set, validation set, test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f58dee-c504-4296-adee-0a41029b9a50",
   "metadata": {},
   "source": [
    "#### Lấy mẫu Stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0612dd-3e80-4902-a756-7bacf3b05970",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified = StratifiedShuffleSplit(test_size=0.3)\n",
    "for train_index, test_index in stratified.split(df['title'], df['label']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "msg_train, label_train = strat_train_set['title'], strat_train_set['label']\n",
    "msg_test, label_test = strat_test_set['title'], strat_test_set['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8237997-1fed-45d9-ac32-e90a5e94ff4f",
   "metadata": {},
   "source": [
    "#### Lấy mẫu Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b3561d-4f5d-4f5b-87f4-e30e4ec10127",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, msg_test2, y2, label_test2 = train_test_split(df['title'], df['label'], test_size=0.3)\n",
    "msg_train2, msg_validation2, label_train2, label_validation2 = train_test_split(x2, y2, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2baab-a6a2-45ce-9d86-af70f73733b3",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a724e3-7ef9-4e7e-88f6-e4942b6c815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61a4a2f2-5c37-486b-bab3-f24325a36571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 10005)\n"
     ]
    }
   ],
   "source": [
    "data_processed = pipeline.fit_transform(msg_train, label_train)\n",
    "msg_train = data_processed\n",
    "print(msg_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92ee03-fbc6-4610-bbec-9e3f72031697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25442c0-259a-4639-aa68-536ba5276c3b",
   "metadata": {},
   "source": [
    "# Lựa chọn tham số tối ưu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0829b-98ff-48ba-b798-28938a3ef3c1",
   "metadata": {},
   "source": [
    "Chỉ dùng tập train để lựa chọn tham số tối ưu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf49f6e-8fc3-45a7-9ab7-c4c4582f974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator):\n",
    "    _, train_scores, test_scores = learning_curve(estimator, msg_train, label_train, cv=10, n_jobs=-1, train_sizes=[1.0, ], scoring=\"accuracy\")\n",
    "    test_scores = test_scores[0]\n",
    "    mean, std = test_scores.mean(), test_scores.std()\n",
    "    return mean, std\n",
    "\n",
    "def plot(title, xlabel, X, Y, error, ylabel = \"Accuracy\"):\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.errorbar(X, Y, error, linestyle='None', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c04ec5-8bbd-4553-abb6-bfd0f030ee28",
   "metadata": {},
   "source": [
    "### Đánh giá độ hiệu quả các kernel trong SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f51b900f-6e77-4e48-8c87-9c07524dcc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████▊                      | 4/5 [57:19<14:19, 859.90s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X should be a square kernel matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 211, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 673, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 282, in _safe_split\n    raise ValueError(\"X should be a square kernel matrix\")\nValueError: X should be a square kernel matrix\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12444/1412282139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12444/4013084631.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[0;32m   1552\u001b[0m                 \u001b[0mtrain_test_proportions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1554\u001b[1;33m         results = parallel(\n\u001b[0m\u001b[0;32m   1555\u001b[0m             delayed(_fit_and_score)(\n\u001b[0;32m   1556\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X should be a square kernel matrix"
     ]
    }
   ],
   "source": [
    "title = \"thay đổi kernel, C = 1\"\n",
    "xlabel = \"kernel\"\n",
    "X = []\n",
    "Y = []\n",
    "error = []\n",
    "\n",
    "for kernel in tqdm(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "    # Với mỗi kernel được chọn, \n",
    "    # thực hiện xây dựng mô hình, huấn luyện và đánh giá theo cross-validation\n",
    "    text_clf = OneVsRestClassifier(SVC(kernel=kernel, C=1.0))\n",
    "    mean, std = cross_validation(text_clf)\n",
    "    X.append(kernel)\n",
    "    Y.append(mean)\n",
    "    error.append(std)\n",
    "\n",
    "# lưu kết quả ra file ảnh \n",
    "plot(title, xlabel, X, Y, error)\n",
    "# plt.savefig('images/svm_change_kernel.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
